import { eq } from 'drizzle-orm';
import type { LibSQLDatabase } from 'drizzle-orm/libsql';
import { testFailures, failureHistory } from '@homelab/db';
import type { AutoGeneratedContent } from '@homelab/validators';
import * as fs from 'fs/promises';
import * as path from 'path';
import {
  extractTestName,
  extractErrorMessage,
  extractStackTrace,
  classifyErrorType,
  inferFixFromErrorType,
  extractAffectedFiles,
  calculatePriority,
  formatTimestamp,
  type ErrorType,
} from '../utils/error-analysis';

/**
 * Error Proposal Generator Service
 *
 * Generates complete OpenSpec proposals from Playwright test failures
 */
export class ErrorProposalGenerator {
  constructor(private db: LibSQLDatabase<any>) {}

  /**
   * Generate a complete proposal from a test failure
   */
  async generateProposal(
    testFailureId: number,
    projectPath: string,
    changeNumber: number
  ): Promise<AutoGeneratedContent> {
    // Fetch test failure
    const failure = await this.db
      .select()
      .from(testFailures)
      .where(eq(testFailures.id, testFailureId))
      .get();

    if (!failure) {
      throw new Error(`Test failure ${testFailureId} not found`);
    }

    // Fetch failure history for classification
    const history = await this.db
      .select()
      .from(failureHistory)
      .where(eq(failureHistory.testName, failure.testName))
      .get();

    const classification = history?.classificationType ?? 'NEW';
    const occurrenceCount = history?.occurrences ?? 1;

    // Extract error information
    const testName = extractTestName(failure.testName, failure.stackTrace ?? undefined);
    const errorMessage = extractErrorMessage(failure.error ?? undefined);
    const stackTrace = extractStackTrace(failure.stackTrace ?? undefined);
    const errorType = classifyErrorType(errorMessage);
    const affectedFiles = extractAffectedFiles(failure.stackTrace ?? undefined);

    // Generate content
    const title = this.generateTitle(testName);
    const why = this.generateWhySection(
      testName,
      errorMessage,
      stackTrace,
      classification,
      history?.firstSeen ?? failure.createdAt,
      history?.lastSeen ?? failure.createdAt,
      occurrenceCount
    );
    const whatChanges = this.generateWhatChanges(errorType, errorMessage, affectedFiles);
    const tasks = this.generateTasks(errorType, testName, affectedFiles);
    const priority = calculatePriority(classification, occurrenceCount);

    return {
      title,
      why,
      whatChanges,
      tasks,
      classification,
      priority,
      errorType,
    };
  }

  /**
   * Generate clean title for the proposal
   */
  private generateTitle(testName: string): string {
    return `Fix: ${testName}`;
  }

  /**
   * Generate the "Why" section with error details
   */
  private generateWhySection(
    testName: string,
    errorMessage: string,
    stackTrace: string,
    classification: 'NEW' | 'FLAKY' | 'RECURRING' | 'PERSISTENT',
    firstSeen: Date,
    lastSeen: Date,
    occurrenceCount: number
  ): string {
    const firstSeenStr = formatTimestamp(firstSeen);
    const lastSeenStr = formatTimestamp(lastSeen);

    return `The test "${testName}" is failing in the test suite.

## Classification
**${classification}** - This error has occurred ${occurrenceCount} time(s).

## Failure Pattern
- **First seen**: ${firstSeenStr}
- **Last seen**: ${lastSeenStr}
- **Total occurrences**: ${occurrenceCount}

## Error Details

\`\`\`
${errorMessage}
\`\`\`

## Stack Trace

\`\`\`
${stackTrace}
\`\`\`

Fixing this test failure will improve test reliability and ensure the feature works as expected.`;
  }

  /**
   * Generate "What Changes" section based on error type
   */
  private generateWhatChanges(
    errorType: ErrorType,
    errorMessage: string,
    affectedFiles: string[]
  ): string {
    const fixSuggestion = inferFixFromErrorType(errorType, errorMessage);

    let changes = `## Suggested Fix\n\n${fixSuggestion}\n\n`;

    if (affectedFiles.length > 0) {
      changes += `## Affected Files\n\n`;
      affectedFiles.forEach(file => {
        changes += `- \`${file}\`\n`;
      });
      changes += '\n';
    }

    changes += `## Implementation Steps\n\n`;
    changes += `1. **Investigate the root cause** - Understand why the test is failing\n`;
    changes += `2. **Implement the fix** - Apply the necessary changes to resolve the error\n`;
    changes += `3. **Add test coverage** - Ensure the fix is covered by tests\n`;
    changes += `4. **Verify** - Run tests to confirm the fix works\n`;

    return changes;
  }

  /**
   * Generate tasks.md content
   */
  private generateTasks(
    errorType: ErrorType,
    testName: string,
    affectedFiles: string[]
  ): string {
    let tasks = `# Implementation Tasks: Fix ${testName}\n\n`;
    tasks += `## Phase 1: Investigation\n\n`;
    tasks += `- [ ] Review test failure details and error message\n`;
    tasks += `- [ ] Analyze stack trace to identify root cause\n`;

    if (affectedFiles.length > 0) {
      tasks += `- [ ] Examine affected files:\n`;
      affectedFiles.forEach(file => {
        tasks += `  - [ ] ${file}\n`;
      });
    }

    tasks += `\n## Phase 2: Implementation\n\n`;

    switch (errorType) {
      case 'type-error':
        tasks += `- [ ] Update type definitions\n`;
        tasks += `- [ ] Ensure type consistency across codebase\n`;
        tasks += `- [ ] Fix type mismatches\n`;
        break;

      case 'missing-property':
        tasks += `- [ ] Add missing property to interface\n`;
        tasks += `- [ ] Update implementation to include property\n`;
        tasks += `- [ ] Provide default value if needed\n`;
        break;

      case 'assertion-failure':
        tasks += `- [ ] Implement missing functionality\n`;
        tasks += `- [ ] Update implementation to match expectations\n`;
        tasks += `- [ ] Verify feature works correctly\n`;
        break;

      case 'network-error':
        tasks += `- [ ] Add retry logic\n`;
        tasks += `- [ ] Implement timeout handling\n`;
        tasks += `- [ ] Add error handling for network failures\n`;
        break;

      case 'configuration-error':
        tasks += `- [ ] Update configuration files\n`;
        tasks += `- [ ] Add missing environment variables\n`;
        tasks += `- [ ] Fix module imports\n`;
        break;

      case 'other':
        tasks += `- [ ] Implement fix based on error analysis\n`;
        tasks += `- [ ] Test the fix thoroughly\n`;
        break;
    }

    tasks += `\n## Phase 3: Testing\n\n`;
    tasks += `- [ ] Run the failing test to verify fix\n`;
    tasks += `- [ ] Run full test suite to ensure no regressions\n`;
    tasks += `- [ ] Add additional test coverage if needed\n`;

    tasks += `\n## Phase 4: Verification\n\n`;
    tasks += `- [ ] Confirm test passes consistently\n`;
    tasks += `- [ ] Update documentation if needed\n`;
    tasks += `- [ ] Mark change as complete\n`;

    return tasks;
  }

  /**
   * Create proposal files on filesystem
   */
  async createProposalFiles(
    content: AutoGeneratedContent,
    projectPath: string,
    changeNumber: number
  ): Promise<string> {
    // Generate change ID from title
    const changeId = `${changeNumber}-${content.title
      .toLowerCase()
      .replace(/^fix:\s*/i, '')
      .replace(/[^a-z0-9]+/g, '-')
      .replace(/^-|-$/g, '')}`;

    const changePath = path.join(projectPath, 'openspec', 'changes', changeId);

    // Create change directory
    await fs.mkdir(changePath, { recursive: true });

    // Create specs directory
    await fs.mkdir(path.join(changePath, 'specs'), { recursive: true });

    // Write proposal.md
    const proposalContent = this.buildProposalMd(content);
    await fs.writeFile(
      path.join(changePath, 'proposal.md'),
      proposalContent,
      'utf-8'
    );

    // Write tasks.md
    await fs.writeFile(
      path.join(changePath, 'tasks.md'),
      content.tasks,
      'utf-8'
    );

    return changeId;
  }

  /**
   * Build complete proposal.md content
   */
  private buildProposalMd(content: AutoGeneratedContent): string {
    return `# ${content.title}

## Why

${content.why}

## What Changes

${content.whatChanges}

## Impact

### Affected Specs
- **test-automation**: MODIFIED - Fix failing test case

### Affected Code
- Test files and implementation code as identified in the error analysis

### Dependencies
- None

### Breaking Changes
None. This is a bug fix.

## Acceptance Criteria

- [ ] Test passes consistently
- [ ] No regressions in other tests
- [ ] Root cause addressed
- [ ] Documentation updated if needed
`;
  }
}
